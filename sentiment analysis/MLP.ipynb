{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fe50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a91cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c94694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./naver_train.csv\", encoding=\"utf-8-sig\")\n",
    "df_test = pd.read_csv(\"./naver_test.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e1521f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터 보고 초딩 영화 줄오버 연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무 재밓었다 그래서 보는 것을 추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다 평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬 페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어 보이기만 했던 커스...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                     흠포스터 보고 초딩 영화 줄오버 연기조차 가볍지 않구나      1\n",
       "2  10265843                             너무 재밓었다 그래서 보는 것을 추천한다      0\n",
       "3   9045019                         교도소 이야기구먼 솔직히 재미는 없다 평점 조정      0\n",
       "4   6483659  사이몬 페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어 보이기만 했던 커스...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78957f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_null(data):\n",
    "    data = data.dropna(axis=0).reset_index(drop=True)\n",
    "    space_idx = []\n",
    "    for i in range(len(data)):\n",
    "        if str.isspace(data.iloc[i, 1]) == True:\n",
    "            space_idx.append(i)\n",
    "    data = data.drop(space_idx)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f384800",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = map(delete_null, [df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab831662",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = np.array(df_train.drop([\"id\"], axis = 1))\n",
    "testset = np.array(df_test.drop([\"id\"], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b274a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset= train_test_split(trainset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eccea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainset[:, 0]\n",
    "y_train = trainset[:, 1]\n",
    "X_val = valset[:, 0]\n",
    "y_val = valset[:, 1]\n",
    "X_test = testset[:, 0]\n",
    "y_test = testset[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d7428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int64)\n",
    "y_val = y_val.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d19b8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mecab(\"C:\\mecab\\mecab-ko-dic\")\n",
    "\n",
    "def tokenizer(text):\n",
    "    return m.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a30327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=tokenizer, max_features=1000)\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_val = vectorizer.transform(X_val).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e78acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134681, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae6e8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y,):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (torch.FloatTensor(self.x[index]), self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0c877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(X_train, y_train)\n",
    "valset = CustomDataset(X_val, y_val)\n",
    "testset = CustomDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0aa46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca376a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu 와 cuda 중 다음 기기로 학슴함:  cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu 와 cuda 중 다음 기기로 학슴함: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b5ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, n_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 500)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        self.fc4 = nn.Linear(125, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logit = self.fc1(x)\n",
    "        logit = self.fc2(logit)\n",
    "        logit = self.fc3(logit)\n",
    "        logit = self.fc4(logit)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b90d1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "model = MLP(1000, n_classes).to(DEVICE)\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deab5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    corrects, total_loss = 0, 0\n",
    "    size = 0\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x , y = batch\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.long().to(DEVICE)\n",
    "        y = y.reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction=\"sum\")\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "        size += x.shape[0]\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92eab1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    size = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_iter:\n",
    "            x , y = batch\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.long().to(DEVICE)\n",
    "            y = y.reshape(-1)\n",
    "            logit = model(x)\n",
    "            loss = F.cross_entropy(logit, y, reduction=\"sum\")\n",
    "            total_loss += loss.item()\n",
    "            corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()    \n",
    "            size += x.shape[0]\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3321f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf1a3fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.423 | Train Acc: 79.98%\n",
      "\t Val. Loss: 0.406 |  Val. Acc: 81.26%\n",
      "Epoch: 02 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.410 | Train Acc: 80.94%\n",
      "\t Val. Loss: 0.407 |  Val. Acc: 81.30%\n",
      "Epoch: 03 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.407 | Train Acc: 81.12%\n",
      "\t Val. Loss: 0.405 |  Val. Acc: 81.31%\n",
      "Epoch: 04 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.406 | Train Acc: 81.15%\n",
      "\t Val. Loss: 0.411 |  Val. Acc: 81.51%\n",
      "Epoch: 05 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.405 | Train Acc: 81.21%\n",
      "\t Val. Loss: 0.403 |  Val. Acc: 81.68%\n",
      "Epoch: 06 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.404 | Train Acc: 81.32%\n",
      "\t Val. Loss: 0.405 |  Val. Acc: 81.42%\n",
      "Epoch: 07 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.404 | Train Acc: 81.16%\n",
      "\t Val. Loss: 0.403 |  Val. Acc: 81.42%\n",
      "Epoch: 08 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.403 | Train Acc: 81.24%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 81.74%\n",
      "Epoch: 09 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.403 | Train Acc: 81.31%\n",
      "\t Val. Loss: 0.403 |  Val. Acc: 81.52%\n",
      "Epoch: 10 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.402 | Train Acc: 81.29%\n",
      "\t Val. Loss: 0.403 |  Val. Acc: 81.50%\n",
      "Epoch: 11 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.402 | Train Acc: 81.37%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 81.40%\n",
      "Epoch: 12 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.402 | Train Acc: 81.32%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 81.66%\n",
      "Epoch: 13 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.402 | Train Acc: 81.42%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 81.53%\n",
      "Epoch: 14 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.401 | Train Acc: 81.38%\n",
      "\t Val. Loss: 0.401 |  Val. Acc: 81.54%\n",
      "Epoch: 15 | Epoch Time: 0m 3s\n",
      "\tTrain Loss: 0.401 | Train Acc: 81.38%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 81.55%\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "n_epochs = 15\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, optimizer, trainloader)\n",
    "    val_loss, val_accuracy = evaluate(model, valloader)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_accuracy:.2f}%')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_accuracy:.2f}%')\n",
    "    \n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), \"./textclassificatior.pt\")\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b28b397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./textclassificatior.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "266acae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81.2108, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate(model, testloader)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607681b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
