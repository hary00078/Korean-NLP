{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2243ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73baca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a539562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train_for_korean.csv\", encoding=\"utf-8-sig\")\n",
    "df_test = pd.read_csv(\"./test_for_korean.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "544f3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(axis=0).reset_index(drop=True)\n",
    "space_idx = []\n",
    "for i in range(len(df_train)):\n",
    "    if str.isspace(df_train.iloc[i, 1]) == True:\n",
    "        space_idx.append(i)\n",
    "df_train = df_train.drop(space_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bb50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.dropna(axis=0).reset_index(drop=True)\n",
    "space_idx = []\n",
    "for i in range(len(df_test)):\n",
    "    if str.isspace(df_test.iloc[i, 1]) == True:\n",
    "        space_idx.append(i)\n",
    "df_test = df_test.drop(space_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a93733",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = np.array(df_train.drop([\"id\"], axis = 1))\n",
    "testset = np.array(df_test.drop([\"id\"], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17470655",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset= train_test_split(trainset, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29570535",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainset[:, 0]\n",
    "y_train = trainset[:, 1]\n",
    "X_val = valset[:, 0]\n",
    "y_val = valset[:, 1]\n",
    "X_test = testset[:, 0]\n",
    "y_test = testset[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d24d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int64)\n",
    "y_val = y_val.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af049921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "bertmodel = bertmodel.from_pretrained(\"kobert_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f82e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af1d1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 64\n",
    "transform = nlp.data.BERTSentenceTransform(\n",
    "            tok, max_seq_length=max_len, pad=True, pair=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9adde35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.idx = torch.tensor([transform([sentence])[0] for sentence in x]).reshape(len(x), -1)\n",
    "        self.l = torch.tensor([transform([sentence])[1].item() for sentence in x])\n",
    "        self.s = torch.tensor([transform([sentence])[2] for sentence in x]).reshape(len(x), -1)\n",
    "        self.y = torch.tensor(y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.idx[index], self.l[index], self.s[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43537ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(X_train, y_train, transform)\n",
    "valset = CustomDataset(X_val, y_val, transform)\n",
    "testset = CustomDataset(X_test, y_test, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054218b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ee083d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e21684b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu 와 cuda 중 다음 기기로 학슴함:  cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu 와 cuda 중 다음 기기로 학슴함: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32cce681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 bert_size = 768,\n",
    "                 hidden_size = 256,\n",
    "                 n_layers = 2,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "        \n",
    "        self.lstm = nn.LSTM(bert_size, hidden_size, num_layers=n_layers, batch_first= True,  bidirectional=True)\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size*2 , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeded = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        \n",
    "        if self.dr_rate:\n",
    "            embeded = self.dropout(embeded[0])\n",
    "        else:\n",
    "            embeded = embeded[0]\n",
    "            \n",
    "        packed_input = pack_padded_sequence(embeded, valid_length.tolist(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output,(hidden, cell) = self.lstm(packed_input)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "        logit = self.classifier(hidden)\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c663fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel).to(DEVICE)\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d2e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdc0d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    corrects, total_loss = 0, 0\n",
    "    size = 0\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x , l, s, y = batch\n",
    "        x = x.to(DEVICE)\n",
    "        l = l.to(DEVICE)\n",
    "        s = s.to(DEVICE)\n",
    "        y = y.long().to(DEVICE)\n",
    "        y = y.reshape(-1)\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(x, l, s)\n",
    "        loss = F.cross_entropy(logit, y, reduction=\"sum\")\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "        size += x.shape[0]\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7530eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    size = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_iter:\n",
    "            x , l, s, y = batch\n",
    "            x = x.to(DEVICE)\n",
    "            l = l.to(DEVICE)\n",
    "            s = s.to(DEVICE)\n",
    "            y = y.long().to(DEVICE)\n",
    "            y = y.reshape(-1)\n",
    "            logit = model(x, l, s)\n",
    "            loss = F.cross_entropy(logit, y, reduction=\"sum\")\n",
    "            total_loss += loss.item()\n",
    "            corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()    \n",
    "            size += x.shape[0]\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "811050ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51a09216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 4m 21s\n",
      "\tTrain Loss: 0.172 | Train Acc: 93.42%\n",
      "\t Val. Loss: 0.179 |  Val. Acc: 93.28%\n",
      "Epoch: 20 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.152 | Train Acc: 94.19%\n",
      "\t Val. Loss: 0.190 |  Val. Acc: 93.16%\n",
      "Epoch: 30 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.118 | Train Acc: 95.57%\n",
      "\t Val. Loss: 0.226 |  Val. Acc: 92.85%\n",
      "Epoch: 40 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.091 | Train Acc: 96.57%\n",
      "\t Val. Loss: 0.266 |  Val. Acc: 92.55%\n",
      "Epoch: 50 | Epoch Time: 4m 14s\n",
      "\tTrain Loss: 0.073 | Train Acc: 97.32%\n",
      "\t Val. Loss: 0.295 |  Val. Acc: 92.84%\n",
      "Epoch: 60 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.060 | Train Acc: 97.81%\n",
      "\t Val. Loss: 0.335 |  Val. Acc: 92.42%\n",
      "Epoch: 70 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.053 | Train Acc: 98.07%\n",
      "\t Val. Loss: 0.357 |  Val. Acc: 92.42%\n",
      "Epoch: 80 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.047 | Train Acc: 98.31%\n",
      "\t Val. Loss: 0.367 |  Val. Acc: 92.64%\n",
      "Epoch: 90 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.042 | Train Acc: 98.45%\n",
      "\t Val. Loss: 0.396 |  Val. Acc: 92.45%\n",
      "Epoch: 100 | Epoch Time: 4m 13s\n",
      "\tTrain Loss: 0.038 | Train Acc: 98.62%\n",
      "\t Val. Loss: 0.391 |  Val. Acc: 92.24%\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "n_epochs = 100\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_accuracy = train(model, optimizer, trainloader)\n",
    "    val_loss, val_accuracy = evaluate(model, valloader)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_accuracy:.2f}%')\n",
    "        print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_accuracy:.2f}%')\n",
    "    \n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), \"./textclassificatior.pt\")\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c786120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./textclassificatior.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93d2c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(88.8724, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate(model, testloader)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13e780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
